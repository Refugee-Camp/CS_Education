# Problem: Is it ethical to accept some casualties caused by self-driving cars

 

Googleâ€™s automated cars have covered nearly a million miles of road with just a few rear-enders, and these vehicles typically deal with uncertain situations by simply stopping.

 

Given the number of fatal traffic accidents that involve human error today, it could be considered unethical to introduce self-driving technology too slowly.

 

Some self-driving cars caused some casualties

Number of casualties that involve human error is vastly higher

It is ethical to introduce self-driving cars technology

 

Some A caused D

Number of D is bigger when H is involved

It it ethical to use A instead of H to reduce D

 

## Analogy

 

This problem is like cars airbags

Airbags save a lot of lives, and only kill a few.

It it ethical to use airbags to reduce number of casualties on the road

 

## Solution

If self-driving car see the obstacle (human, another car or an animal) on the way it has to avoid it.

If it's impossible for self-driving car to avoid obstacle (human, another car or an animal) it has to stop.

If self-driving car stop at hight speed (more then 80 m/h) airbags should explode to protect driver and passengers.  

 

## Test and conformation 

 

We need to conduct 100 field tests to confirm that technology is safe enough to use it on a streets.

If in 95% of the tests car come to complete stop and neither object in either lane is struck by the car should be observed, then we can conclude that use self-driving cars on a streets is safe enough.

 

If the car coming to a complete stop would solve the dilemma is true, then neither object in either lane is struck by the car should be observed.

Neither object is struck by the car when it comes to a complete stop is observed.

Therefore the car coming to a complete stop would solves dilemma is probably true.

 
